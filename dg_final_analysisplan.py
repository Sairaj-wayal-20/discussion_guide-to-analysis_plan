# -*- coding: utf-8 -*-
"""dg_final_analysisplan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q_Od1rcv9lbhlnGUa_D93Ewi2g9MQxWt
"""

import warnings
warnings.filterwarnings("ignore")
import pandas as pd

from docx import Document
import re
import nltk
from nltk import sent_tokenize, word_tokenize, pos_tag
import docx
import sys
# Download NLTK data (if not already downloaded)
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

from openai import OpenAI
client = OpenAI(api_key='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')

filename=sys.argv[1]
document_path =f"static/files/{filename}"

section_with_questions = pd.DataFrame(columns=['Section', 'Question'])

doc = Document(document_path)
section_name = ''

for i, paragraph in enumerate(doc.paragraphs):
  text = paragraph.text

  # Is this a section name?
  if paragraph.style.name.startswith('Heading') and 'section ' in text.lower():
    # If length of next index is 35 or less chars, its possibly section name (get it without duration) and its not objective
    next_index_text = doc.paragraphs[i+1].text.replace("\t", "").replace("\n", "")
    next_index_text = re.sub(r'\(\d+ mins\)', '', next_index_text).strip()
    if len(next_index_text) < 36 and not next_index_text.lower().startswith("objective"):
      section_name = next_index_text
    else:
      # Remove section in text
      text = ' '.join(text.split()[2:])
      # Remove mins
      text = re.sub(r'\(\d+ mins\)', '', text).strip()
      section_name = re.sub(r'\(\d+ minutes\)', '', text).strip()
    continue

  # Does text ends with question mark?
  if text.endswith("?"):
    new_row = pd.DataFrame({"Section": [section_name], "Question": [text]})
    section_with_questions = pd.concat([section_with_questions, new_row], ignore_index=True)
    continue

  # Does NLTK thinks this is a question?
  words = word_tokenize(text)
  pos_tags = pos_tag(words)

  # Check for specific verb patterns
  if len(pos_tags) >= 3:
    if pos_tags[0][1] == 'VB' and pos_tags[1][1] == 'PRP' and pos_tags[2][1] in ['VB', 'VBP']:
      new_row = pd.DataFrame({"Section": [section_name], "Question": [text]})
      section_with_questions = pd.concat([section_with_questions, new_row], ignore_index=True)
      continue

  # Check for "what", "who", "whom", "whose", "why", "where", etc
  if pos_tags and pos_tags[0][1] in ['WDT', 'WP', 'WP$', 'WRB']:
    new_row = pd.DataFrame({"Section": [section_name], "Question": [text]})
    section_with_questions = pd.concat([section_with_questions, new_row], ignore_index=True)

#section_with_questions

question=" "
for i, row in section_with_questions.iterrows():
  question += str(i + 1) + ")" + row["Question"] +"\n"

def questions(data):
  completion = client.chat.completions.create(
          model="gpt-3.5-turbo-1106",
          messages=[
              {
                  "role": "system",
                  "content": """Combine sub-questions with their corresponding main questions in the dataset. Keep the original main questions intact without skipping any.
                                Avoid adding sub-question numbers and store the combined content into the previous main questions. Optimize the output while maintaining the meaning of the questions. Each question must be separated using a "\n".
                                also give the output sequence form as like a input and don't skip the question give input as output
                                stick to the output
                                Questions -
                """,
              },
              {"role": "user", "content": data},
          ],
      )
  return completion.choices[0].message.content

output = questions(question)

result=output.split("\n")

#result

df1 = pd.DataFrame(columns=["section","tags","Questions"])

#df1

for q in result:
    if q == "" :
      continue
    df1 = df1.append({"Questions": q} , ignore_index=True)

#df1

question_tag=" "
for i, item in enumerate(result):
  question_tag += str(i + 1) + ")" + item +"\n"

def tags(data):
    responses = []
    for question in data:
        print(data)
    completion = client.chat.completions.create(
    model="gpt-3.5-turbo-1106",
    messages=[
                {
                    "role": "system",
                    "content": """I want to create a shorter, concise version and topic of just giving the answer  strictly in  3-5 words and also giving each question for each tag.dont add extra tags

                                Here are some examples -

                                Actual Question - Without giving away anything personally identifiable, can you please briefly introduce yourself and tell me a little bit about your practice setting?
                                Short Version - introduce yourself and  practice setting

                                Actual Question - Approximately how many patients do you see in a typical month for major depressive disorder (MDD)?
                                Short Version - patients you see in a month for MDD

                                Actual Question - How do you define MDD? How do they think about symptoms? Part of MDD or separate, even if potentially related (anxiety, anhedonia, insomnia)?
                                Short Version - define MDD, about symptoms, Part of MDD or separate anxiety, anhedonia, insomnia

                                Now do it for below question. Answer output only, no heading,no Question number, context or pretext.
                """,
                },
                {"role": "user", "content": data},
            ],
        )
    responses.append(completion.choices[0].message.content)
    return responses

tag_output = tags(question_tag)

tag_output = re.split('\n', ','.join(tag_output))

#tag_output

tag_output_without_numbers = [item.split(') ', 1)[1] for item in tag_output]

#print(tag_output_without_numbers)

df1["tags"]=tag_output_without_numbers

df1["section"]=section_with_questions["Section"]

#df1
df1.to_excel(f"static/files/Analysis-Plan-{filename}.xlsx", index=False)
#df1.to_excel("output-23034 cEGFR Unbranded Message and Concept Testing DG_forHIVE_v6.0 CLEAN -US-UK-Canada.xlsx", index=False)

from docx import Document
from docx.enum.text import WD_COLOR_INDEX

def highlight_text(doc, column_values):
    for paragraph in doc.paragraphs:
        if all(value not in paragraph.text for value in column_values):
            for run in paragraph.runs:
                run.font.highlight_color = WD_COLOR_INDEX.YELLOW

# Assuming df is your DataFrame and "col" is the column you want to use
column_to_highlight = section_with_questions['Question'].tolist()

# Assuming document_path is the path to your Word document
doc = Document(document_path)

highlight_text(doc, column_to_highlight)

# Save the modified document
doc.save('static/files/unselected-highlighted.docx')


import zipfile
import os

# File paths
output_file1 = f"static/files/Analysis-Plan-{filename}.xlsx"
output_file2 = 'static/files/unselected-highlighted.docx'
zip_file_name = f"static/files/output-{filename}.zip"

# Create a Zip file
with zipfile.ZipFile(zip_file_name, 'w') as zip_file:
    # Add files to the Zip file
    zip_file.write(output_file1,f"output-{filename}.xlsx" )
    zip_file.write(output_file2, 'unselected-highlighted.docx')